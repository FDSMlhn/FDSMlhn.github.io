<!DOCTYPE html>












  


<html class="theme-next mist use-motion" lang="zh-CN">
<head><meta name="generator" content="Hexo 3.8.0">
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
























<link rel="stylesheet" href="/lib/font-awesome/css/font-awesome.min.css?v=4.7.0">

<link rel="stylesheet" href="/css/main.css?v=7.1.2">


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=7.1.2">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=7.1.2">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=7.1.2">


  <link rel="mask-icon" href="/images/logo.svg?v=7.1.2" color="#222">







<script id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Mist',
    version: '7.1.2',
    sidebar: {"position":"left","display":"post","offset":12,"onmobile":false,"dimmer":false},
    back2top: true,
    back2top_sidebar: false,
    fancybox: false,
    fastclick: false,
    lazyload: false,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>


  




  <meta name="description" content="This passage will lead you through the whole process of the implementation of image classification tasks on CIFAR-10 and also explain some confusing parts for beginners in detail. Besides, I also put">
<meta name="keywords" content="-hexo">
<meta property="og:type" content="article">
<meta property="og:title" content="Deep Residual Learning For Image Recognition">
<meta property="og:url" content="http://fdsmlhn.github.io/2018/02/09/Deep-Residual-Learning-For-Image-Recognition/index.html">
<meta property="og:site_name" content="Nevermore">
<meta property="og:description" content="This passage will lead you through the whole process of the implementation of image classification tasks on CIFAR-10 and also explain some confusing parts for beginners in detail. Besides, I also put">
<meta property="og:locale" content="zh-CN">
<meta property="og:image" content="http://fdsmlhn.github.io/2018/02/09/Deep-Residual-Learning-For-Image-Recognition/main_files/main_5_1.png">
<meta property="og:image" content="http://fdsmlhn.github.io/2018/02/09/Deep-Residual-Learning-For-Image-Recognition/main_files/main_11_0.png">
<meta property="og:updated_time" content="2018-02-10T03:55:16.653Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Deep Residual Learning For Image Recognition">
<meta name="twitter:description" content="This passage will lead you through the whole process of the implementation of image classification tasks on CIFAR-10 and also explain some confusing parts for beginners in detail. Besides, I also put">
<meta name="twitter:image" content="http://fdsmlhn.github.io/2018/02/09/Deep-Residual-Learning-For-Image-Recognition/main_files/main_5_1.png">





  
  
  <link rel="canonical" href="http://fdsmlhn.github.io/2018/02/09/Deep-Residual-Learning-For-Image-Recognition/">



<script id="page.configurations">
  CONFIG.page = {
    sidebar: "",
  };
</script>

  <title>Deep Residual Learning For Image Recognition | Nevermore</title>
  












  <noscript>
  <style>
  .use-motion .motion-element,
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-title { opacity: initial; }

  .use-motion .logo,
  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript><!-- hexo-inject:begin --><!-- hexo-inject:end -->

<link rel="stylesheet" href="/css/prism-tomorrow.css" type="text/css"></head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-CN">

  
  
    
  

  <!-- hexo-inject:begin --><!-- hexo-inject:end --><div class="container sidebar-position-left page-post-detail">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta">
    

    <div class="custom-logo-site-title">
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Nevermore</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
    
      
        <p class="site-subtitle">Just begins.</p>
      
    
    
  </div>

  <div class="site-nav-toggle">
    <button aria-label="切换导航栏">
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>



<nav class="site-nav">
  
    <ul id="menu" class="menu">
      
        
        
        
          
          <li class="menu-item menu-item-home">

    
    
    
      
    

    

    <a href="/" rel="section"><i class="menu-item-icon fa fa-fw fa-home"></i> <br>首页</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-about">

    
    
    
      
    

    

    <a href="/about/" rel="section"><i class="menu-item-icon fa fa-fw fa-user"></i> <br>关于</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-archives">

    
    
    
      
    

    

    <a href="/archives/" rel="section"><i class="menu-item-icon fa fa-fw fa-archive"></i> <br>归档</a>

  </li>

      
      
    </ul>
  

  
    

  

  
</nav>



  



</div>
    </header>

    


    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://fdsmlhn.github.io/2018/02/09/Deep-Residual-Learning-For-Image-Recognition/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Haonan Li">
      <meta itemprop="description" content="Strong Mind = Success">
      <meta itemprop="image" content="/images/selfie1.JPG">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Nevermore">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">Deep Residual Learning For Image Recognition

              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              

              
                
              

              <time title="创建时间：2018-02-09 18:28:09 / 修改时间：19:55:16" itemprop="dateCreated datePublished" datetime="2018-02-09T18:28:09-08:00">2018-02-09</time>
            

            
              

              
            
          </span>

          

          
            
            
              
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
            
                <span class="post-meta-item-text">评论数：</span>
                <a href="/2018/02/09/Deep-Residual-Learning-For-Image-Recognition/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count disqus-comment-count" data-disqus-identifier="2018/02/09/Deep-Residual-Learning-For-Image-Recognition/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          
            <span id="/2018/02/09/Deep-Residual-Learning-For-Image-Recognition/" class="leancloud_visitors" data-flag-title="Deep Residual Learning For Image Recognition">
              <span class="post-meta-divider">|</span>
              <span class="post-meta-item-icon">
                <i class="fa fa-eye"></i>
              </span>
              
                <span class="post-meta-item-text">阅读次数：</span>
              
                <span class="leancloud-visitors-count"></span>
            </span>
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <hr>
<p>This passage will lead you through the whole process of the implementation of image classification tasks on CIFAR-10 and also explain some confusing parts for beginners in detail. Besides, I also put down what I've learned in the middle and hope you will at least grasp how you should build up the whole pipeline of conv net at last. <a id="more"></a></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#notebook setup</span></span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">from</span> torch.nn <span class="keyword">import</span> init</span><br><span class="line"><span class="keyword">from</span> torch.autograd <span class="keyword">import</span> Variable</span><br><span class="line"><span class="keyword">import</span> torchvision</span><br><span class="line"><span class="keyword">import</span> torchvision.transforms <span class="keyword">as</span> T</span><br><span class="line"><span class="keyword">import</span> torch.optim <span class="keyword">as</span> optim</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> DataLoader</span><br><span class="line"><span class="keyword">from</span> torch.utils.data.sampler <span class="keyword">import</span> SubsetRandomSampler</span><br><span class="line"><span class="keyword">import</span> torchvision.datasets <span class="keyword">as</span> dset</span><br><span class="line"><span class="keyword">import</span> torch.backends.cudnn <span class="keyword">as</span> cudnn</span><br><span class="line"><span class="keyword">from</span> torch.optim.lr_scheduler <span class="keyword">import</span> MultiStepLR</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> utils <span class="keyword">import</span> progress_bar</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> matplotlib</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> matplotlib.gridspec <span class="keyword">as</span> gridspec</span><br><span class="line"></span><br><span class="line">%matplotlib inline</span><br><span class="line">plt.rcParams[<span class="string">'figure.figsize'</span>] = (<span class="number">10.0</span>, <span class="number">8.0</span>) <span class="comment"># set default size of plots</span></span><br><span class="line">plt.rcParams[<span class="string">'image.interpolation'</span>] = <span class="string">'nearest'</span></span><br><span class="line">plt.rcParams[<span class="string">'image.cmap'</span>] = <span class="string">'gray'</span></span><br><span class="line"></span><br><span class="line">%load_ext autoreload</span><br><span class="line">%autoreload <span class="number">2</span></span><br></pre></td></tr></table></figure>
<pre><code>The autoreload extension is already loaded. To reload it, use:
  %reload_ext autoreload</code></pre>
<p>And also some useful function:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">show_images</span><span class="params">(imgs)</span>:</span></span><br><span class="line">    NUM = imgs.shape[<span class="number">0</span>]</span><br><span class="line">    </span><br><span class="line">    sqrtn = int(np.ceil(np.sqrt(NUM)))</span><br><span class="line">    sqrtimg = int(np.ceil(np.sqrt(NUM)))</span><br><span class="line"></span><br><span class="line">    fig = plt.figure(figsize=(sqrtn, sqrtn))</span><br><span class="line">    gs = gridspec.GridSpec(sqrtn, sqrtn)</span><br><span class="line">    gs.update(wspace=<span class="number">0.05</span>, hspace=<span class="number">0.05</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> i, img <span class="keyword">in</span> enumerate(imgs):</span><br><span class="line">        ax = plt.subplot(gs[i])</span><br><span class="line">        plt.axis(<span class="string">'off'</span>)</span><br><span class="line">        ax.set_xticklabels([])</span><br><span class="line">        ax.set_yticklabels([])</span><br><span class="line">        ax.set_aspect(<span class="string">'equal'</span>)</span><br><span class="line">        plt.imshow(img)</span><br><span class="line">    <span class="keyword">return</span></span><br></pre></td></tr></table></figure>
<p>First we need to download the data if needed. And then preprocess as following:</p>
<ol type="1">
<li>4 pixels padding and random cropping</li>
<li>flipping randomly</li>
<li>normalize</li>
</ol>
<hr>
<p>The intuition behind them are explained <a href="https://stackoverflow.com/questions/32842308/random-cropping-and-flipping-in-convolutional-neural-networks/32844299" target="_blank" rel="noopener">here</a>:</p>
<blockquote>
<p>This is referred to as <strong>data augmentation</strong>. By applying transformations to the training data, you're adding synthetic data points. This exposes the model to additional variations without the cost of collecting and annotating more data. This can have the effect of reducing overfitting and improving the model's ability to generalize.</p>
</blockquote>
<blockquote>
<p>The intuition behind <strong>flipping</strong> an image is that an object should be equally recognizable as its mirror image. Note that horizontal flipping is the type of flipping often used. Vertical flipping doesn't always make sense but this depends on the data.</p>
</blockquote>
<blockquote>
<p>The idea behind <strong>cropping</strong> is that to reduce the contribution of the background in the CNNs decision. That's useful if you have labels for locating where your object is. This lets you use surrounding regions as negative examples and building a better detector. Random cropping can also act as a regularizer and base your classification on the presence of parts of the object <em>instead of focusing everything on a very distinct feature</em> that may not always be present.</p>
</blockquote>
<p>And a very approaching idea on random cropping:</p>
<blockquote>
<p>I think random cropping also associate a broader range of spatial activation statistics with a certain class label and thus makes the algorithm more robust.</p>
</blockquote>
<hr>
<p>Some tips here: 1. just mentioned CIFAR in PyTorch will load all data into memory at the beginning, not too large. 2. T.ToTensor will convert img in the range [0,255] to that in [0,1]. Some codes Normalize them using (0.5,0.5,0.5) to rescale it to range(-1,1) after ToTensor operation.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># size of the image dataset N * 32 * 32 * 3</span></span><br><span class="line">NUM_TRAIN = <span class="number">45000</span></span><br><span class="line">NUM_VAL = <span class="number">5000</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">train_CIFAR = dset.CIFAR10(<span class="string">'../datasets/'</span>, train=<span class="keyword">True</span>, download=<span class="keyword">True</span>)</span><br><span class="line">train_mean = np.mean(train_CIFAR.train_data, axis=(<span class="number">0</span>,<span class="number">1</span>,<span class="number">2</span>))/<span class="number">255</span></span><br><span class="line">train_std = np.std(train_CIFAR.train_data, axis=(<span class="number">0</span>,<span class="number">1</span>,<span class="number">2</span>))/<span class="number">255</span></span><br><span class="line"></span><br><span class="line">train_transform = T.Compose([</span><br><span class="line">    T.RandomCrop(<span class="number">32</span>, padding=<span class="number">4</span>),</span><br><span class="line">    T.RandomHorizontalFlip(),</span><br><span class="line">    T.ToTensor(),</span><br><span class="line">    T.Normalize(train_mean, train_std)</span><br><span class="line">])</span><br><span class="line"></span><br><span class="line">test_transform = T.Compose([</span><br><span class="line">    T.ToTensor(),</span><br><span class="line">    T.Normalize(train_mean, train_std)</span><br><span class="line">])</span><br><span class="line">train_CIFAR = dset.CIFAR10(<span class="string">'../datasets/'</span>, train=<span class="keyword">True</span>, download=<span class="keyword">True</span>, transform = train_transform)</span><br><span class="line">train_loader = DataLoader(train_CIFAR, batch_size = <span class="number">128</span>, num_workers=<span class="number">2</span>, </span><br><span class="line">                          sampler= SubsetRandomSampler(list(range(NUM_TRAIN))))</span><br><span class="line">val_loader = DataLoader(train_CIFAR, batch_size = <span class="number">128</span>, num_workers=<span class="number">2</span>, </span><br><span class="line">                          sampler= SubsetRandomSampler(list(range(NUM_TRAIN,(NUM_TRAIN+NUM_VAL)))))</span><br><span class="line"></span><br><span class="line">test_CIFAR = dset.CIFAR10(<span class="string">'../datasets/'</span>, train=<span class="keyword">False</span>, download=<span class="keyword">True</span>, transform= test_transform)</span><br><span class="line">test_loader = DataLoader(test_CIFAR, batch_size = <span class="number">128</span>, num_workers=<span class="number">2</span>, shuffle=<span class="keyword">False</span>)</span><br><span class="line"></span><br><span class="line">NUM_SHOW = <span class="number">16</span></span><br><span class="line"></span><br><span class="line">img =train_CIFAR.train_data[:NUM_SHOW,:]</span><br><span class="line">show_images(img)</span><br></pre></td></tr></table></figure>
<pre><code>Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified</code></pre>
<figure>
<img src="main_files/main_5_1.png" alt="png"><figcaption>png</figcaption>
</figure>
<p>Then we will import Resnet-18 to train our dataset on the training data. These two models use different architecture, one with basic block and the other with one called bottleneck. I specifically choose these two different sorts of models with relatively less layers due to the limit of the computational resources.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> resnet <span class="keyword">import</span> Resnet18</span><br><span class="line"></span><br><span class="line">net = Resnet18()</span><br><span class="line"></span><br><span class="line">criterion = nn.CrossEntropyLoss()</span><br><span class="line"></span><br><span class="line"><span class="comment">#Adam does not perform so good here</span></span><br><span class="line">optimizer = optim.SGD(net.parameters(), lr=<span class="number">0.1</span>, momentum=<span class="number">0.9</span>, weight_decay=<span class="number">8e-4</span>, nesterov= <span class="keyword">True</span>)</span><br><span class="line">scheduler = MultiStepLR(optimizer, [<span class="number">100</span>,<span class="number">150</span>], gamma=<span class="number">0.1</span>)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br></pre></td><td class="code"><pre><span class="line">use_cuda = torch.cuda.is_available()</span><br><span class="line"></span><br><span class="line">print(<span class="string">'GPU %s available on this machine!'</span> %(<span class="string">'is'</span> <span class="keyword">if</span> use_cuda <span class="keyword">else</span> <span class="string">'is not'</span> ))</span><br><span class="line"><span class="keyword">if</span> use_cuda:</span><br><span class="line">    net.cuda()</span><br><span class="line">    net = torch.nn.DataParallel(net, device_ids=range(torch.cuda.device_count()))</span><br><span class="line">    cudnn.benchmark = <span class="keyword">True</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">train</span><span class="params">(epoch)</span>:</span></span><br><span class="line">    <span class="keyword">global</span> train_data</span><br><span class="line">    loss_hist = []</span><br><span class="line">    train_acc_hist = []</span><br><span class="line">    val_acc_hist = []</span><br><span class="line">    test_acc_hist = []</span><br><span class="line">    train_data=&#123;&#125;</span><br><span class="line">    train_data[<span class="string">'loss_hist'</span>] = loss_hist</span><br><span class="line">    train_data[<span class="string">'train_acc_hist'</span>] = train_acc_hist</span><br><span class="line">    train_data[<span class="string">'val_acc_hist'</span>] =  val_acc_hist</span><br><span class="line">    train_data[<span class="string">'test_acc_hist'</span>] =  test_acc_hist</span><br><span class="line">    </span><br><span class="line">    </span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(epoch):</span><br><span class="line">        print(<span class="string">'This is epoch:&#123;&#125;'</span>.format(i+<span class="number">1</span>))</span><br><span class="line">        total= <span class="number">0</span></span><br><span class="line">        correct=<span class="number">0</span></span><br><span class="line">        scheduler.step()</span><br><span class="line">        net.train()</span><br><span class="line">        <span class="keyword">for</span> j,(batch_x, batch_y) <span class="keyword">in</span> enumerate(train_loader):</span><br><span class="line">            optimizer.zero_grad()</span><br><span class="line">            <span class="keyword">if</span> use_cuda:</span><br><span class="line">                batch_x, batch_y = batch_x.cuda(), batch_y.cuda()</span><br><span class="line">            x = Variable(batch_x)</span><br><span class="line">            y = Variable(batch_y)</span><br><span class="line">            out = net(x)</span><br><span class="line">            loss = criterion(out, y)</span><br><span class="line">            loss.backward()</span><br><span class="line">            optimizer.step()</span><br><span class="line">            </span><br><span class="line">            _, predicted = torch.max(out.data, <span class="number">1</span>)</span><br><span class="line">            total += y.size(<span class="number">0</span>)</span><br><span class="line">            correct += predicted.eq(y.data).cpu().sum()</span><br><span class="line">            progress_bar(j, len(train_loader), <span class="string">'Loss: %.3f | Acc: %.3f%% (%d/%d)'</span></span><br><span class="line">                % (loss.data[<span class="number">0</span>], <span class="number">100.</span>*correct/total, correct, total))</span><br><span class="line">            <span class="keyword">if</span> j % <span class="number">50</span>==<span class="number">0</span>:</span><br><span class="line">                loss_hist.append(loss.data[<span class="number">0</span>])</span><br><span class="line">            </span><br><span class="line">        train_acc_hist.append(<span class="number">100.</span>*correct/total)</span><br><span class="line">        <span class="keyword">if</span> i %<span class="number">1</span> == <span class="number">0</span>:</span><br><span class="line">            acc = test(val_loader)</span><br><span class="line">            val_acc_hist.append(acc)</span><br><span class="line">            print(<span class="string">'Epoch &#123;&#125;, loss: &#123;&#125;, accuracy: &#123;&#125;'</span>.format(i+<span class="number">1</span>, loss_hist[<span class="number">-1</span>], acc))</span><br><span class="line">            acc = test(test_loader)</span><br><span class="line">            test_acc_hist.append(acc)</span><br><span class="line">            print(<span class="string">'Epoch &#123;&#125;, loss: &#123;&#125;, accuracy: &#123;&#125;'</span>.format(i+<span class="number">1</span>, loss_hist[<span class="number">-1</span>], acc))</span><br><span class="line">                </span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">test</span><span class="params">(val_load)</span>:</span></span><br><span class="line">    net.eval()</span><br><span class="line">    total = <span class="number">0</span></span><br><span class="line">    positive = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> val_x, val_y <span class="keyword">in</span> val_load:</span><br><span class="line">        <span class="keyword">if</span> use_cuda:</span><br><span class="line">            val_x, val_y = val_x.cuda(), val_y.cuda()</span><br><span class="line">        x = Variable(val_x)</span><br><span class="line">        y = Variable(val_y)</span><br><span class="line">        out = net(x)</span><br><span class="line">        <span class="comment">#print(out.size())</span></span><br><span class="line">        positive += (torch.max(out,<span class="number">1</span>)[<span class="number">1</span>]==y).sum().data[<span class="number">0</span>]</span><br><span class="line">        total += out.size()[<span class="number">0</span>]</span><br><span class="line">    acc =  (positive*<span class="number">100.0</span>)/total</span><br><span class="line">    <span class="keyword">return</span> acc     </span><br><span class="line"></span><br><span class="line">train(<span class="number">200</span>)</span><br></pre></td></tr></table></figure>
<p>I use total 200 epoches. Thanks to the GPU, the training time for each epoch is merely 1.25 minutes, which is a drastically cut compared to almost 50 minutes via CPU. Then, I will try to visualise the whole training process and see what happens in the process.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pickle</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> open(<span class="string">'resnet18data.pkl'</span>,<span class="string">'wb'</span>) <span class="keyword">as</span> f:</span><br><span class="line">    pickle.dump(train_data,f)</span><br><span class="line"><span class="keyword">with</span> open(<span class="string">'resnet18data.pkl'</span>, <span class="string">'rb'</span>) <span class="keyword">as</span> f:</span><br><span class="line">    train_data = pickle.load(f)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line">plt.style.use(<span class="string">'seaborn-white'</span>)</span><br><span class="line">plt.rc(<span class="string">'font'</span>, size=<span class="number">20</span>)</span><br><span class="line">plt.rc(<span class="string">'axes'</span>, titlesize=<span class="number">20</span>)</span><br><span class="line">plt.rc(<span class="string">'axes'</span>, labelsize=<span class="number">20</span>)    <span class="comment"># fontsize of the x and y labels</span></span><br><span class="line">plt.rc(<span class="string">'xtick'</span>, labelsize=<span class="number">20</span>)    <span class="comment"># fontsize of the tick labels</span></span><br><span class="line"></span><br><span class="line">gs = gridspec.GridSpec(<span class="number">2</span>,<span class="number">1</span>)</span><br><span class="line">gs.update(hspace=<span class="number">0.5</span>)</span><br><span class="line">fig = plt.figure(figsize=(<span class="number">16</span>,<span class="number">10</span>))</span><br><span class="line">fig1 = fig.add_subplot(gs[<span class="number">0</span>,<span class="number">0</span>])</span><br><span class="line">fig2 = fig.add_subplot(gs[<span class="number">1</span>,<span class="number">0</span>])</span><br><span class="line">fig1.spines[<span class="string">'right'</span>].set_visible(<span class="keyword">False</span>)</span><br><span class="line">fig1.spines[<span class="string">'top'</span>].set_visible(<span class="keyword">False</span>)</span><br><span class="line"><span class="comment"># for item in [fig1.xaxis.label, fig1.yaxis.label,fig2.xaxis.label, fig2.yaxis.label]:</span></span><br><span class="line"><span class="comment">#     item.set_fontsize(10)</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">fig1.plot([i * <span class="number">0.005</span> <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">1</span>,len(train_data[<span class="string">'loss_hist'</span>])+<span class="number">1</span>)],train_data[<span class="string">'loss_hist'</span>],color=<span class="string">'black'</span>)</span><br><span class="line">fig1.set(title= <span class="string">'Loss trajectory of training'</span>,ylabel=<span class="string">'Loss'</span>,xlabel=<span class="string">'Iter.(1e4)'</span>)</span><br><span class="line"></span><br><span class="line">fig2.plot([<span class="number">100</span>-i <span class="keyword">for</span> i <span class="keyword">in</span> train_data[<span class="string">'train_acc_hist'</span>]], color=<span class="string">'red'</span>,linestyle=<span class="string">'-.'</span>,label = <span class="string">'train'</span>)</span><br><span class="line">fig2.plot([<span class="number">100</span>-i <span class="keyword">for</span> i <span class="keyword">in</span> train_data[<span class="string">'test_acc_hist'</span>]], color=<span class="string">'blue'</span>,linestyle=<span class="string">'-'</span>,label=<span class="string">'test'</span>)</span><br><span class="line">fig2.plot([<span class="number">100</span>-i <span class="keyword">for</span> i <span class="keyword">in</span> train_data[<span class="string">'val_acc_hist'</span>]], color=<span class="string">'green'</span>,linestyle=<span class="string">'-'</span>,label=<span class="string">'val'</span>)</span><br><span class="line">fig2.legend(frameon=<span class="keyword">True</span>)</span><br><span class="line">fig2.spines[<span class="string">'right'</span>].set_visible(<span class="keyword">False</span>)</span><br><span class="line">fig2.spines[<span class="string">'top'</span>].set_visible(<span class="keyword">False</span>)</span><br><span class="line">fig2.axhline(y=[<span class="number">5</span>],alpha=<span class="number">0.5</span>, linestyle=<span class="string">'--'</span>,color=<span class="string">'k'</span>,linewidth=<span class="number">1</span>)</span><br><span class="line">fig2.axhline(y=[<span class="number">10</span>],alpha=<span class="number">0.5</span>, linestyle=<span class="string">'--'</span>,color=<span class="string">'k'</span>,linewidth=<span class="number">1</span>)</span><br><span class="line">_=fig2.set(title= <span class="string">'Top-1 Accuracy of Resnet18 on CIFAR-10'</span>,ylim=(<span class="number">0</span>,<span class="number">20</span>),xlabel=<span class="string">'Epoch'</span>,ylabel=<span class="string">'Error(%)'</span>)</span><br><span class="line"><span class="comment">#fig.plot()</span></span><br></pre></td></tr></table></figure>
<figure>
<img src="main_files/main_11_0.png" alt="png"><figcaption>png</figcaption>
</figure>
<p>There are two things we need to pay attention to:</p>
<ol type="1">
<li><p>The training process stagnates quickly after we adjust the learning rate, which indicates we can actually cut some training time after the adjustment and proceed without the loss of performance.</p></li>
<li><p>We can see that the both loss and error drop drastically after we decrease the learning rate by a factor of 0.1, it may tell us we can further improve the performance by adding more lr decreasing stage. Although the marginal gain is apparently decreasing as we can expect.</p></li>
</ol>
<p>And interestingly, the model does not show a evident tendency to overfit the data after the second time we adjust the learning rate. Maybe part of the reason is the error rate is very close to zero in the last stage. So the classifier has no further space to improve and overfit the data. It also give use some hints that maybe we can increase the weight decay to make our network better!</p>
<p>And next I will shed some light on the resnet-50 without actually running it.</p>
<p>The resnet-50 or more layers like 101 or 152 use a different architecture called Bottleneck. The intuition behind this is more of practical consideration. It works better than just stacking layers in the BasicBlock from 2 to 3. We can see that part of the reason is that the bottleneck structure cuts some parameters due to the 1x1 conv layer, which first reduces the input dimension and then restores the output dimension, and makes network deeper while keeping the time complexity the same as the basicblock of 2-layer version. As a result, the degradation problem will be less severe compared with one using basicblock to have 50 or more layers as we can expect.</p>

      
    </div>

    

    
    
    

    
      <div id="wechat_subscriber" style="display: block; padding: 10px 0; margin: 20px auto; width: 100%; text-align: center;">
  <img id="wechat_subscriber_qcode" src="/images/wechat_qcode.JPG" alt="Haonan Li wechat" style="width: 200px; max-width: 100%;">
  <div></div>
</div>

    

    
      
    
    

    

    <footer class="post-footer">
      
        
          
        
        <div class="post-tags">
          
            <a href="/tags/hexo/" rel="tag"># -hexo</a>
          
        </div>
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2017/11/02/Understanding im2col implementation in Python(numpy fancy indexing)/" rel="next" title="Understanding im2col implementation in Python(numpy fancy indexing)">
                <i class="fa fa-chevron-left"></i> Understanding im2col implementation in Python(numpy fancy indexing)
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/2018/08/12/Advanced-Tensorflow-Usage-and-Experiment-from-input-fn-to-modelling-part/" rel="prev" title="Advanced Tensorflow Usage and Experiment: from input_fn to modelling part">
                Advanced Tensorflow Usage and Experiment: from input_fn to modelling part <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>


  </div>


          </div>
          

  
    <div class="comments" id="comments">
      <div id="disqus_thread">
        <noscript>Please enable JavaScript to view the comments powered by Disqus.</noscript>
      </div>
    </div>

  



        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    <div class="sidebar-inner">

      

      

      <div class="site-overview-wrap sidebar-panel sidebar-panel-active">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <img class="site-author-image" itemprop="image" src="/images/selfie1.JPG" alt="Haonan Li">
            
              <p class="site-author-name" itemprop="name">Haonan Li</p>
              <div class="site-description motion-element" itemprop="description">Strong Mind = Success</div>
          </div>

          
            <nav class="site-state motion-element">
              
                <div class="site-state-item site-state-posts">
                
                  <a href="/archives/">
                
                    <span class="site-state-item-count">4</span>
                    <span class="site-state-item-name">日志</span>
                  </a>
                </div>
              

              

              
                
                
                <div class="site-state-item site-state-tags">
                  
                    
                    
                      
                    
                      
                    
                      
                    
                      
                    
                    <span class="site-state-item-count">4</span>
                    <span class="site-state-item-name">标签</span>
                  
                </div>
              
            </nav>
          

          

          

          
            <div class="links-of-author motion-element">
              
                <span class="links-of-author-item">
                  
                  
                    
                  
                  
                    
                  
                  <a href="https://github.com/fdsmlhn" title="GitHub &rarr; https://github.com/fdsmlhn" rel="noopener" target="_blank"><i class="fa fa-fw fa-github"></i>GitHub</a>
                </span>
              
                <span class="links-of-author-item">
                  
                  
                    
                  
                  
                    
                  
                  <a href="mailto:lihaonan@uw.edu" title="E-Mail &rarr; mailto:lihaonan@uw.edu" rel="noopener" target="_blank"><i class="fa fa-fw fa-envelope"></i>E-Mail</a>
                </span>
              
            </div>
          

          

          
          

          
            
          
          

        </div>
      </div>

      

      

    </div>
  </aside>
  


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; 2017 – <span itemprop="copyrightYear">2019</span>
  <span class="with-love" id="animate">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Haonan Li</span>

  

  
</div>


  <div class="powered-by">由 <a href="https://hexo.io" class="theme-link" rel="noopener" target="_blank">Hexo</a> 强力驱动 v3.8.0</div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">主题 – <a href="https://theme-next.org" class="theme-link" rel="noopener" target="_blank">NexT.Mist</a> v7.1.2</div>




        








        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

    

    
  </div>

  

<script>
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>


























  
  <script src="/lib/jquery/index.js?v=3.4.1"></script>

  
  <script src="/lib/velocity/velocity.min.js?v=1.2.1"></script>

  
  <script src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>


  


  <script src="/js/utils.js?v=7.1.2"></script>

  <script src="/js/motion.js?v=7.1.2"></script>



  
  


  <script src="/js/schemes/muse.js?v=7.1.2"></script>




  
  <script src="/js/scrollspy.js?v=7.1.2"></script>
<script src="/js/post-details.js?v=7.1.2"></script>



  


  <script src="/js/next-boot.js?v=7.1.2"></script>


  

  

  

  
  
<script>
  function loadCount() {
    var d = document, s = d.createElement('script');
    s.src = 'https://haonanli.disqus.com/count.js';
    s.id = 'dsq-count-scr';
    (d.head || d.body).appendChild(s);
  }
  // defer loading until the whole page loading is completed
  window.addEventListener('load', loadCount, false);
</script>


<script>
  var disqus_config = function() {
    this.page.url = "http://fdsmlhn.github.io/2018/02/09/Deep-Residual-Learning-For-Image-Recognition/";
    this.page.identifier = "2018/02/09/Deep-Residual-Learning-For-Image-Recognition/";
    this.page.title = 'Deep Residual Learning For Image Recognition';
    };
  function loadComments() {
    var d = document, s = d.createElement('script');
    s.src = 'https://haonanli.disqus.com/embed.js';
    s.setAttribute('data-timestamp', '' + +new Date());
    (d.head || d.body).appendChild(s);
  }
  
    window.addEventListener('load', loadComments, false);
  
</script>





  


  




  
  
  <script>
    
    function addCount(Counter) {
      var $visitors = $('.leancloud_visitors');
      var url = $visitors.attr('id').trim();
      var title = $visitors.attr('data-flag-title').trim();

      Counter('get', '/classes/Counter', { where: JSON.stringify({ url }) })
        .done(function({ results }) {
          if (results.length > 0) {
            var counter = results[0];
            
            Counter('put', '/classes/Counter/' + counter.objectId, JSON.stringify({ time: { '__op': 'Increment', 'amount': 1 } }))
            
              .done(function() {
                var $element = $(document.getElementById(url));
                $element.find('.leancloud-visitors-count').text(counter.time + 1);
              })
            
              .fail(function ({ responseJSON }) {
                console.log('Failed to save Visitor num, with error message: ' + responseJSON.error);
              })
          } else {
            
              Counter('post', '/classes/Counter', JSON.stringify({ title: title, url: url, time: 1 }))
                .done(function() {
                  var $element = $(document.getElementById(url));
                  $element.find('.leancloud-visitors-count').text(1);
                })
                .fail(function() {
                  console.log('Failed to create');
                });
            
          }
        })
        .fail(function ({ responseJSON }) {
          console.log('LeanCloud Counter Error: ' + responseJSON.code + ' ' + responseJSON.error);
        });
    }
    

    $(function() {
      $.get('https://app-router.leancloud.cn/2/route?appId=' + 'zbvuaBisX1AfjuwJMcWO9rzv-gzGzoHsz')
        .done(function({ api_server }) {
          var Counter = function(method, url, data) {
            return $.ajax({
              method: method,
              url: 'https://' + api_server + '/1.1' + url,
              headers: {
                'X-LC-Id': 'zbvuaBisX1AfjuwJMcWO9rzv-gzGzoHsz',
                'X-LC-Key': '3b93yKO3H6npVFDdtYKfwSYA',
                'Content-Type': 'application/json',
              },
              data: data
            });
          };
          
            addCount(Counter);
          
        });
    });
  </script>



  

  
  

  
  

  
    
      <script type="text/x-mathjax-config">
  

  MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [ ['$', '$'], ['\\(', '\\)'] ],
      processEscapes: true,
      skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
    },
    TeX: {
      
      equationNumbers: {
        autoNumber: 'AMS'
      }
    }
  });
  MathJax.Hub.Register.StartupHook('TeX Jax Ready', function() {
    MathJax.InputJax.TeX.prefilterHooks.Add(function(data) {
      if (data.display) {
        var next = data.script.nextSibling;
        while (next && next.nodeName.toLowerCase() === '#text') { next = next.nextSibling }
        if (next && next.nodeName.toLowerCase() === 'br') { next.parentNode.removeChild(next) }
      }
    });
  });
</script>

<script type="text/x-mathjax-config">
  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for (i = 0; i < all.length; i += 1) {
      document.getElementById(all[i].inputID + '-Frame').parentNode.className += ' has-jax';
    }
  });
</script>
<script src="//cdn.staticfile.org/MathJax/MathJax-2.6-latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>

    
  


  

  

  

  

  

  

  

  

  
<script>
  $('.highlight').not('.gist .highlight').each(function(i, e) {
    var $wrap = $('<div>').addClass('highlight-wrap');
    $(e).after($wrap);
    $wrap.append($('<button>').addClass('copy-btn').append('复制').on('click', function(e) {
      var code = $(this).parent().find('.code').find('.line').map(function(i, e) {
        return $(e).text();
      }).toArray().join('\n');
      var ta = document.createElement('textarea');
      var yPosition = window.pageYOffset || document.documentElement.scrollTop;
      ta.style.top = yPosition + 'px'; // Prevent page scroll
      ta.style.position = 'absolute';
      ta.style.opacity = '0';
      ta.readOnly = true;
      ta.value = code;
      document.body.appendChild(ta);
      const selection = document.getSelection();
      const selected = selection.rangeCount > 0 ? selection.getRangeAt(0) : false;
      ta.select();
      ta.setSelectionRange(0, code.length);
      ta.readOnly = false;
      var result = document.execCommand('copy');
      
      ta.blur(); // For iOS
      $(this).blur();
      if (selected) {
        selection.removeAllRanges();
        selection.addRange(selected);
      }
    })).on('mouseleave', function(e) {
      var $b = $(this).find('.copy-btn');
      setTimeout(function() {
        $b.text('复制');
      }, 300);
    }).append(e);
  })
</script><!-- hexo-inject:begin --><!-- Begin: Injected MathJax -->
<script type="text/x-mathjax-config">
  MathJax.Hub.Config("");
</script>

<script type="text/x-mathjax-config">
  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
      all[i].SourceElement().parentNode.className += ' has-jax';
    }
  });
</script>

<script type="text/javascript" src>
</script>
<!-- End: Injected MathJax -->
<!-- hexo-inject:end -->


  

  

</body>
</html>
